{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LSoLpIlUm5Re",
        "hIwij04llq9w",
        "lp1Q4uCVluA3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch_xla[tpu] -f https://storage.googleapis.com/libtorch-xla-releases/wheels/tpuvm/colab.html # Only if you wanna use tpus on colab"
      ],
      "metadata": {
        "id": "G8gYC-L5D_xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10/KMEANS paper/ResNET-18 (ignore this; older)"
      ],
      "metadata": {
        "id": "LSoLpIlUm5Re"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Blh-3A-rDKYy",
        "outputId": "fb423528-418f-4e34-e71a-3b42219f3a51"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5fdfebc28062>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCosineAnnealingLR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mefficientnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgooglenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStochasticDepth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_presets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgiou_loss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneralized_box_iou_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv3dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrozenBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSqueezeExcitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_align\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/roi_align.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_compile_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBroadcastingList2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ordered_set\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_traceable_wrapper_subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m from torch.utils._sympy.functions import (\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mApplication\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mCeilToInt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_sympy/functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msympify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlazy_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'dev'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAtom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msingleton\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAtomicExpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnevaluatedExpr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnumbers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRational\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInteger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumberSymbol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/core/expr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAtom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msingleton\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevalf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvalfMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpure_complex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_MAXPREC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcall_highest_priority\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msympify_method_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msympify_return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcacheit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet18\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "# from sklearn.cluster import KMeans\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "\n",
        "\"\"\"Dataset part\"\"\"\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=10000, shuffle=True)\n",
        "val_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
        "\n",
        "\n",
        "mean_image = 0.0\n",
        "total_samples = 0\n",
        "denom = 0.0\n",
        "\n",
        "for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader, desc=\"Loading CIFAR-10\")):\n",
        "    batch_samples = inputs.size(0)\n",
        "    mean_image += inputs.sum(dim=0)  # sum over batch dimension -> shape (C, H, W)\n",
        "    total_samples += batch_samples\n",
        "\n",
        "mean_image /= total_samples\n",
        "mu_flat = mean_image.view(1, -1)\n",
        "\n",
        "for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader, desc=\"Computing denominator\")):\n",
        "    # inputs: shape (B, C, H, W)\n",
        "    batch_flat = inputs.view(inputs.size(0), -1)\n",
        "\n",
        "    # Compute squared distance to mean for each sample in batch\n",
        "    dists_squared = ((batch_flat - mu_flat) ** 2).sum(dim=1)\n",
        "\n",
        "    # Sum\n",
        "    denom += dists_squared.sum().item()\n",
        "\n",
        "q_values = torch.empty(total_samples) # Our q(x)\n",
        "start_idx = 0\n",
        "\n",
        "for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader, desc=\"Computing q(x) for all dataset indices\")):\n",
        "    batch_size = inputs.size(0)\n",
        "    end_idx = start_idx + batch_size\n",
        "\n",
        "    # Compute squared distances to the mean\n",
        "    batch_flat = inputs.view(batch_size, -1)\n",
        "    dists_squared = ((batch_flat - mu_flat) ** 2).sum(dim=1)\n",
        "\n",
        "    # Compute q(x)\n",
        "    q_batch = 0.5 * (1 / total_samples) + 0.5 * (dists_squared / denom)\n",
        "    q_values[start_idx:end_idx] = q_batch\n",
        "\n",
        "    start_idx = end_idx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 / q(x)\n",
        "sampling_probs = (1.0 / q_values)\n",
        "sampling_probs /= sampling_probs.sum()  # normalize to sum to 1\n",
        "\n",
        "m = 20000  # TODO Use the general way later\n",
        "sample_indices = torch.multinomial(sampling_probs, num_samples=m, replacement=False)\n",
        "\n",
        "coreset = Subset(train_dataset, sample_indices.tolist())\n",
        "coreset_loader = torch.utils.data.DataLoader(coreset, batch_size=2048, shuffle=False)"
      ],
      "metadata": {
        "id": "kUzxW_4dHlBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EiLEKBomcEgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Training model part\"\"\"\n",
        "\n",
        "# Use MPS if available (for Macs), otherwise fallback\n",
        "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = xm.xla_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load ResNet18\n",
        "\n",
        "model = resnet18(num_classes=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=300)\n",
        "\n",
        "# Training loop\n",
        "def train(model, train_loader, epochs=300):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        para_loader = pl.MpDeviceLoader(train_loader, device)\n",
        "        loop = tqdm(para_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\")\n",
        "\n",
        "        for inputs, targets in loop:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(optimizer)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            loop.set_postfix(loss=running_loss/(total/inputs.size(0)), acc=100.*correct/total)\n",
        "\n",
        "        scheduler.step()\n",
        "    return model\n",
        "\n",
        "# Validation loop\n",
        "def validate(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        para_loader = pl.MpDeviceLoader(val_loader, device)\n",
        "        for inputs, targets in para_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    acc = 100. * correct / total\n",
        "    print(f\"Validation Accuracy: {acc:.2f}%\")\n",
        "\n",
        "# Main entry\n",
        "model = train(model, coreset_loader, epochs=35)\n",
        "validate(model, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpDam-d5ELSn",
        "outputId": "def4f9e5-a70b-4a55-d805-7e01fe045871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: xla:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/35]: 100%|██████████| 10/10 [01:02<00:00,  6.27s/it, acc=20.4, loss=1.71]\n",
            "Epoch [2/35]: 100%|██████████| 10/10 [00:04<00:00,  2.42it/s, acc=36.4, loss=1.37]\n",
            "Epoch [3/35]: 100%|██████████| 10/10 [00:04<00:00,  2.19it/s, acc=45.3, loss=1.19]\n",
            "Epoch [4/35]: 100%|██████████| 10/10 [00:04<00:00,  2.38it/s, acc=51.5, loss=1.05]\n",
            "Epoch [5/35]: 100%|██████████| 10/10 [00:04<00:00,  2.31it/s, acc=58.2, loss=0.92]\n",
            "Epoch [6/35]: 100%|██████████| 10/10 [00:04<00:00,  2.38it/s, acc=64, loss=0.805]\n",
            "Epoch [7/35]: 100%|██████████| 10/10 [00:04<00:00,  2.35it/s, acc=69.3, loss=0.701]\n",
            "Epoch [8/35]: 100%|██████████| 10/10 [00:04<00:00,  2.20it/s, acc=71.7, loss=0.653]\n",
            "Epoch [9/35]: 100%|██████████| 10/10 [00:04<00:00,  2.35it/s, acc=73.5, loss=0.603]\n",
            "Epoch [10/35]: 100%|██████████| 10/10 [00:04<00:00,  2.39it/s, acc=78.2, loss=0.508]\n",
            "Epoch [11/35]: 100%|██████████| 10/10 [00:04<00:00,  2.33it/s, acc=83.8, loss=0.397]\n",
            "Epoch [12/35]: 100%|██████████| 10/10 [00:04<00:00,  2.37it/s, acc=87.4, loss=0.32]\n",
            "Epoch [13/35]: 100%|██████████| 10/10 [00:04<00:00,  2.20it/s, acc=90.3, loss=0.249]\n",
            "Epoch [14/35]: 100%|██████████| 10/10 [00:04<00:00,  2.32it/s, acc=92, loss=0.209]\n",
            "Epoch [15/35]: 100%|██████████| 10/10 [00:04<00:00,  2.41it/s, acc=93, loss=0.18]\n",
            "Epoch [16/35]: 100%|██████████| 10/10 [00:04<00:00,  2.37it/s, acc=94.9, loss=0.139]\n",
            "Epoch [17/35]: 100%|██████████| 10/10 [00:04<00:00,  2.28it/s, acc=96.8, loss=0.0968]\n",
            "Epoch [18/35]: 100%|██████████| 10/10 [00:04<00:00,  2.44it/s, acc=97.7, loss=0.0729]\n",
            "Epoch [19/35]: 100%|██████████| 10/10 [00:04<00:00,  2.40it/s, acc=98, loss=0.0641]\n",
            "Epoch [20/35]: 100%|██████████| 10/10 [00:04<00:00,  2.49it/s, acc=98.5, loss=0.053]\n",
            "Epoch [21/35]: 100%|██████████| 10/10 [00:04<00:00,  2.42it/s, acc=99, loss=0.0353]\n",
            "Epoch [22/35]: 100%|██████████| 10/10 [00:04<00:00,  2.32it/s, acc=99.5, loss=0.0189]\n",
            "Epoch [23/35]: 100%|██████████| 10/10 [00:04<00:00,  2.42it/s, acc=99.6, loss=0.0134]\n",
            "Epoch [24/35]: 100%|██████████| 10/10 [00:04<00:00,  2.41it/s, acc=99.6, loss=0.0132]\n",
            "Epoch [25/35]: 100%|██████████| 10/10 [00:04<00:00,  2.41it/s, acc=99, loss=0.0267]\n",
            "Epoch [26/35]: 100%|██████████| 10/10 [00:04<00:00,  2.36it/s, acc=98.8, loss=0.0333]\n",
            "Epoch [27/35]: 100%|██████████| 10/10 [00:04<00:00,  2.31it/s, acc=99, loss=0.0276]\n",
            "Epoch [28/35]: 100%|██████████| 10/10 [00:04<00:00,  2.41it/s, acc=99.5, loss=0.0172]\n",
            "Epoch [29/35]: 100%|██████████| 10/10 [00:04<00:00,  2.41it/s, acc=99.8, loss=0.00773]\n",
            "Epoch [30/35]: 100%|██████████| 10/10 [00:04<00:00,  2.21it/s, acc=100, loss=0.00344]\n",
            "Epoch [31/35]: 100%|██████████| 10/10 [00:04<00:00,  2.44it/s, acc=100, loss=0.00216]\n",
            "Epoch [32/35]: 100%|██████████| 10/10 [00:04<00:00,  2.41it/s, acc=100, loss=0.00164]\n",
            "Epoch [33/35]: 100%|██████████| 10/10 [00:04<00:00,  2.34it/s, acc=100, loss=0.00139]\n",
            "Epoch [34/35]: 100%|██████████| 10/10 [00:04<00:00,  2.26it/s, acc=100, loss=0.00123]\n",
            "Epoch [35/35]: 100%|██████████| 10/10 [00:04<00:00,  2.38it/s, acc=100, loss=0.00113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 52.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forests/Kmeans paper/RBFNN paper/kmeans++"
      ],
      "metadata": {
        "id": "vUm4e-0mHddU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the data\n",
        "X, y = fetch_covtype(return_X_y=True)\n",
        "\n",
        "print(f\"Original Shape of X: {X.shape}\")\n",
        "\n",
        "# Normalize X to be between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "print(f\"After normalization, min value: {X.min()}, max value: {X.max()}\")"
      ],
      "metadata": {
        "id": "N8saRH_KnH0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a6ef52-4f3f-4996-c6a6-bd3037138813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Shape of X: (581012, 54)\n",
            "After normalization, min value: 0.0, max value: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lightweight coreset"
      ],
      "metadata": {
        "id": "hIwij04llq9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LightweightCoreset:\n",
        "    def __init__(self, X, k, eps):\n",
        "        self.X = X\n",
        "        self.k = k\n",
        "        self.eps = eps\n",
        "\n",
        "    def set_k(self, k):\n",
        "        self.k = k\n",
        "\n",
        "    def set_X(self, X):\n",
        "        self.X = X\n",
        "\n",
        "    def _compute_m(self):\n",
        "        #Computing coreset size\n",
        "        self.m = np.int64(self.X.shape[1]*self.k*np.log2(self.k)/np.power(self.eps, 2))\n",
        "        if self.m > self.X.shape[0]*0.2:\n",
        "            self.m = int(self.k * 0.01 * self.X.shape[0])\n",
        "\n",
        "    def _compute_coreset(self):\n",
        "        #Algorithm 1 Lightweight coreset construction\n",
        "        dist = np.power(self.X-self.X.mean(axis=0), 2).sum(axis=1)\n",
        "        q = 0.5/self.X.shape[0] + 0.5*dist/dist.sum()\n",
        "        indices = np.random.choice(self.X.shape[0], size=self.m, replace=True)\n",
        "        X_cs = self.X[indices, :]\n",
        "        w_cs = 1.0/(self.m*q[indices])\n",
        "        return X_cs, w_cs\n",
        "\n",
        "    def compute(self):\n",
        "        self._compute_m()\n",
        "        print(\"coreset size: \", self.m)\n",
        "        return self._compute_coreset()"
      ],
      "metadata": {
        "id": "ZgtT3bBoShwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RBFNN coreset"
      ],
      "metadata": {
        "id": "lp1Q4uCVluA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import approx_fprime\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import ConvexHull\n",
        "from scipy.io import loadmat\n",
        "import time\n",
        "import numpy.linalg as la\n",
        "import copy\n",
        "from mpl_toolkits import mplot3d\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "np.seterr(all='raise')\n",
        "\n",
        "\n",
        "class MVEEApprox(object):\n",
        "    Epsilon = 1e-6\n",
        "\n",
        "    def __init__(self, P, cost_func, maxIter=10, bound=1):\n",
        "        self.cost_func = cost_func\n",
        "        self.P = P\n",
        "        self.bound = bound\n",
        "        self.maxIter = maxIter\n",
        "        self.c = np.zeros((P.shape[1], ))\n",
        "        self.G = max(np.sqrt(P.shape[0]), np.max(np.sum(np.abs(P)**2,axis=-1)**(0.5))) * np.eye(P.shape[1], P.shape[1])\n",
        "        self.oldG = copy.deepcopy(self.G)\n",
        "\n",
        "\n",
        "    def separation_oracle(self, x):\n",
        "        # grad = approx_fprime(x, self.cost_func, self.Epsilon)\n",
        "        grad = self.P.T.dot(np.sign(self.P.dot(x)))\n",
        "        return grad / np.linalg.norm(grad, np.inf)\n",
        "\n",
        "    def get_axis_points(self):\n",
        "        if np.any(np.isnan(self.G)):\n",
        "            raise ValueError('WHATT!!!!')\n",
        "        U, s, vh = np.linalg.svd(self.G, full_matrices=True)\n",
        "        # volume = np.prod(np.sqrt(s))\n",
        "        d = s.shape[0]\n",
        "        A = np.dot(np.diag(np.sqrt(s) / np.sqrt(d + 1)), U.T)\n",
        "        points = np.vstack((A, -A))\n",
        "        # points = np.tile(, vh.T)), d, axis=0)\n",
        "        # temp = np.repeat(np.vstack((self.c[:, np.newaxis].T, -self.c[:, np.newaxis].T)), d, axis=0)\n",
        "        temp = np.tile(self.c[:, np.newaxis].T, (2*d, 1))\n",
        "        return points + temp\n",
        "\n",
        "    def check_if_inside(self, P):\n",
        "        #vals = np.apply_along_axis(self.cost_func, 1, P)\n",
        "        vals = np.linalg.norm(P.dot(self.P.T), ord=1, axis=1)\n",
        "        i = np.argmax(vals, axis=0)\n",
        "        if vals[i] <= 1:\n",
        "            return np.inf, vals[i]\n",
        "\n",
        "        print('Maximal Value: {:.4f}'.format(vals[i]))\n",
        "\n",
        "        return i, vals[i]\n",
        "\n",
        "    def basic_ellipsoid_method(self):\n",
        "        d = np.ma.size(self.P, axis=1)\n",
        "\n",
        "        self.oldG = copy.deepcopy(self.G)\n",
        "        while self.cost_func(self.c) > 1 :\n",
        "            H = self.separation_oracle(self.c)\n",
        "            b = np.dot(self.G, H) / np.sqrt(np.abs(np.dot(H, np.dot(self.G, H))))\n",
        "            self.c = self.c - 1.0 / (d + 1.0) * b\n",
        "            self.G = d ** 2.0 / (d ** 2.0 - 1.0) * (self.G - (2.0 / (d + 1.0)) * np.dot(b[:, np.newaxis], b[:, np.newaxis].T))\n",
        "\n",
        "        if not self.isPD(self.G):\n",
        "            print('Corrected back to PSD at Basic ellipsoid method')\n",
        "            self.G = self.nearestPD(self.G)\n",
        "\n",
        "\n",
        "    def shallow_cut_update(self, point):\n",
        "        d = np.ma.size(self.G, 0)\n",
        "        rho = 1.0 / (d + 1.0) ** 2.0\n",
        "        sigma = d ** 3.0 * (d + 2.0) / ((d + 1) ** 3.0 * (d - 1.0))\n",
        "        zeta = 1.0 + 1.0 / (2.0 * d ** 2.0 * (d + 1.0) ** 2.0)\n",
        "        tau = 2.0 / ((d + 1.0) * d)\n",
        "\n",
        "        b = np.dot(self.G, point) / np.sqrt(np.abs(np.dot(point, np.dot(self.G, point))))\n",
        "        self.oldG = copy.deepcopy(self.G)\n",
        "        self.G = zeta * sigma * (self.G - tau * np.dot(b[:, np.newaxis], b[:, np.newaxis].T))\n",
        "        self.c = self.c - rho * b\n",
        "\n",
        "        if not self.isPD(self.G):\n",
        "            print('Corrected back to PSD at Shallow cut update')\n",
        "            self.G = self.nearestPD(self.G)\n",
        "\n",
        "    def compute_approximated_MVEE(self):\n",
        "        stop = False\n",
        "        iter = 0\n",
        "        while not stop:\n",
        "            s = time.time()\n",
        "            self.basic_ellipsoid_method()\n",
        "            print(time.time() - s)\n",
        "\n",
        "            s = time.time()\n",
        "            axis_points = self.get_axis_points()\n",
        "            print(time.time() - s)\n",
        "            i, val = self.check_if_inside(axis_points)\n",
        "            if np.isinf(i):\n",
        "                stop = True\n",
        "            else:\n",
        "                sep_grad = self.separation_oracle(axis_points[i, :])\n",
        "                self.shallow_cut_update(sep_grad)\n",
        "\n",
        "            if iter > self.maxIter:\n",
        "                self.G = self.G / val\n",
        "                iter = 0\n",
        "                print('HMM')\n",
        "                continue\n",
        "            iter += 1\n",
        "\n",
        "        E = np.linalg.cholesky(self.G)\n",
        "        return E, self.c\n",
        "\n",
        "    @staticmethod\n",
        "    def nearestPD(A):\n",
        "        \"\"\"Find the nearest positive-definite matrix to input\n",
        "\n",
        "        A Python/Numpy port of John D'Errico's nearestSPD MATLAB code [1], which\n",
        "        credits [2].\n",
        "\n",
        "        [1] https://www.mathworks.com/matlabcentral/fileexchange/42885-nearestspd\n",
        "\n",
        "        [2] N.J. Higham, \"Computing a nearest symmetric positive semidefinite\n",
        "        matrix\" (1988): https://doi.org/10.1016/0024-3795(88)90223-6\n",
        "        \"\"\"\n",
        "\n",
        "        B = (A + A.T) / 2\n",
        "        _, s, V = la.svd(B)\n",
        "\n",
        "        H = np.dot(V.T, np.dot(np.diag(s), V))\n",
        "\n",
        "        A2 = (B + H) / 2\n",
        "\n",
        "        A3 = (A2 + A2.T) / 2\n",
        "\n",
        "        if MVEEApprox.isPD(A3):\n",
        "            return A3\n",
        "\n",
        "        spacing = np.spacing(la.norm(A))\n",
        "        # The above is different from [1]. It appears that MATLAB's chol Cholesky\n",
        "        # decomposition will accept matrixes with exactly 0-eigenvalue, whereas\n",
        "        # Numpy's will not. So where [1] uses eps(mineig) (where eps is Matlab\n",
        "        # for np.spacing), we use the above definition. CAVEAT: our spacing\n",
        "        # will be much larger than [1]'s eps(mineig), since mineig is usually on\n",
        "        # the order of 1e-16, and eps(1e-16) is on the order of 1e-34, whereas\n",
        "        # spacing will, for Gaussian random matrixes of small dimension, be on\n",
        "        # othe order of 1e-16. In practice, both ways converge, as the unit test\n",
        "        # below suggests.\n",
        "        I = np.eye(A.shape[0])\n",
        "        k = 1\n",
        "        while not MVEEApprox.isPD(A3):\n",
        "            mineig = np.min(np.real(la.eigvals(A3)))\n",
        "            A3 += I * (-mineig * k ** 2 + spacing)\n",
        "            k += 1\n",
        "\n",
        "        return A3\n",
        "\n",
        "    @staticmethod\n",
        "    def isPD(B):\n",
        "        \"\"\"Returns true when input is positive-definite, via Cholesky\"\"\"\n",
        "        try:\n",
        "            _ = la.cholesky(B)\n",
        "            return True\n",
        "        except la.LinAlgError:\n",
        "            return False\n",
        "\n",
        "    @staticmethod\n",
        "    def plotEllipsoid(center, radii, rotation, ax=None, plotAxes=True, cageColor='r', cageAlpha=1):\n",
        "        \"\"\"Plot an ellipsoid\"\"\"\n",
        "        make_ax = (ax is None)\n",
        "        if make_ax:\n",
        "            fig = plt.figure()\n",
        "            ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "        u = np.linspace(0.0, 2.0 * np.pi, 100)\n",
        "        v = np.linspace(0.0, np.pi, 100)\n",
        "\n",
        "        # cartesian coordinates that correspond to the spherical angles:\n",
        "        x = radii[0] * np.outer(np.cos(u), np.sin(v))\n",
        "        y = radii[1] * np.outer(np.sin(u), np.sin(v))\n",
        "        z = radii[2] * np.outer(np.ones_like(u), np.cos(v))\n",
        "        # rotate accordingly\n",
        "        for i in range(len(x)):\n",
        "            for j in range(len(x)):\n",
        "                [x[i, j], y[i, j], z[i, j]] = np.dot(np.array([x[i, j], y[i, j], z[i, j]]), rotation) + center.flatten()\n",
        "\n",
        "        if plotAxes:\n",
        "            # make some purdy axes\n",
        "            axes = np.array([[radii[0], 0.0, 0.0],\n",
        "                             [0.0, radii[1], 0.0],\n",
        "                             [0.0, 0.0, radii[2]]])\n",
        "            # rotate accordingly\n",
        "            for i in range(len(axes)):\n",
        "                axes[i] = np.dot(axes[i], rotation)\n",
        "\n",
        "            print('Axis are: ', axes)\n",
        "            # print(axes + center.flatten())\n",
        "\n",
        "            # plot axes\n",
        "            print('Whole points are: ')\n",
        "            for p in axes:\n",
        "                X3 = np.linspace(-p[0], p[0], 2) + center[0]\n",
        "                Y3 = np.linspace(-p[1], p[1], 2) + center[1]\n",
        "                Z3 = np.linspace(-p[2], p[2], 2) + center[2]\n",
        "                ax.plot3D(X3, Y3, Z3, color='m')\n",
        "                PP = np.vstack((X3, Y3, Z3)).T\n",
        "                print(PP)\n",
        "\n",
        "        # plot ellipsoid\n",
        "        ax.plot_wireframe(x, y, z, rstride=4, cstride=4, color=cageColor, alpha=cageAlpha)\n",
        "        plt.show()\n",
        "\n",
        "    def plotBodyAndEllips(self, B, E):\n",
        "        N = 10000\n",
        "        U, D, V = np.linalg.svd(E, full_matrices=True)\n",
        "        a = D[0]\n",
        "        b = D[1]\n",
        "        theta = np.expand_dims(np.arange(start=0, step=1.0 / N, stop=2.0 * np.pi + 1.0 / N), 1).T\n",
        "\n",
        "        state = np.vstack((a * np.cos(theta), b * np.sin(theta)))\n",
        "        X = np.dot(U, state) + self.c[:, np.newaxis]\n",
        "\n",
        "        ax = plt.subplot(111)\n",
        "        plt.plot(X[0, :], X[1, :], color='black', linewidth=5)\n",
        "\n",
        "        vals = np.apply_along_axis(lambda x: np.linalg.norm(x.flatten() - self.c.flatten()), 0, X)\n",
        "        i = np.argmax(vals)\n",
        "\n",
        "        print(X[:, i])\n",
        "\n",
        "        plt.scatter(self.c[0], self.c[1], marker='+', color='green')\n",
        "        plt.grid(True)\n",
        "\n",
        "        # hull = ConvexHull(B)\n",
        "        # for simplex in hull.simplices:\n",
        "        #     plt.plot(B[simplex, 0], B[simplex, 1], 'k-')\n",
        "\n",
        "        # plt.scatter(B[:, 0], B[:, 1], marker='D', color='orange')\n",
        "\n",
        "        # plt.scatter(self.c[0], self.c[1], marker='^', color='green')\n",
        "        # plt.scatter(X[0, i], X[1, i], marker='*', color='black')\n",
        "        plt.scatter(B[:, 0], B[:, 1], marker='*', color='green')\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def main():\n",
        "        P = np.random.rand(10000, 400)\n",
        "        cost_func = lambda x: np.linalg.norm(np.dot(P, x), ord=1)\n",
        "        tol = 1/100\n",
        "        start_time = time.time()\n",
        "\n",
        "        mvee = MVEEApprox(P, cost_func, maxIter=10)\n",
        "        E, C = mvee.compute_approximated_MVEE()\n",
        "\n",
        "        print('Ellip took {:.4f}'.format(time.time() - start_time))\n",
        "        if P.shape[1] <= 3:\n",
        "            N = 1000\n",
        "            X = np.random.randn(N, P.shape[1])\n",
        "            vals = np.apply_along_axis(cost_func, 1, X)\n",
        "            X = np.multiply(X, 1.0 / vals[:, np.newaxis])\n",
        "            if P.shape[1] == 2:\n",
        "                mvee.plotBodyAndEllips(X, E)\n",
        "            else:\n",
        "                fig = plt.figure()\n",
        "                ax = plt.axes(projection='3d')\n",
        "\n",
        "                # from scipy.spatial import ConvexHull\n",
        "                # hull = ConvexHull(X)\n",
        "\n",
        "                # Plot defining corner points\n",
        "                # ax.plot(X.T[0], X.T[1], X.T[2], \"ko\")\n",
        "                # for s in hull.simplices:\n",
        "                #     s = np.append(s, s[0])  # Here we cycle back to the first coordinate\n",
        "                #     ax.plot(X[s, 0], X[s, 1], X[s, 2], \"b-\")\n",
        "                ax.scatter3D(X[:, 0], X[:, 1], X[:, 2], color='black', marker='o')\n",
        "                U, D, V = la.svd(E, full_matrices=True)\n",
        "                mvee.plotEllipsoid(C, D, U.T, ax=ax)\n",
        "\n",
        "R = 10\n",
        "\n",
        "def obtainSensitivity(X, w, approxMVEE=False):\n",
        "    if not approxMVEE:\n",
        "        raise Exception\n",
        "    else:\n",
        "        cost_func = lambda x: np.linalg.norm(np.dot(X, x), ord=1)\n",
        "        mvee = MVEEApprox(X, cost_func, 3)\n",
        "        ellipsoid, center = mvee.compute_approximated_MVEE()\n",
        "        U = X.dot(ellipsoid)\n",
        "        return np.linalg.norm(U, ord=1, axis=1)\n",
        "\n",
        "\n",
        "def generateCoreset(X, y, sensitivity, sample_size, weights=None, SEED=1):\n",
        "    if weights is None:\n",
        "        weights = np.ones((X.shape[0], 1)).flatten()\n",
        "\n",
        "    # Compute the sum of sensitivities.\n",
        "    t = np.sum(sensitivity)\n",
        "\n",
        "    # The probability of a point prob(p_i) = s(p_i) / t\n",
        "    probability = sensitivity.flatten() / t\n",
        "\n",
        "    startTime = time.time()\n",
        "\n",
        "    # initialize new seed\n",
        "    np.random.seed()\n",
        "\n",
        "    # Multinomial Distribution\n",
        "    hist = np.random.choice(np.arange(probability.shape[0]), size=sample_size, replace=False, p=probability.flatten())\n",
        "    indxs, counts = np.unique(hist, return_counts=True)\n",
        "    S = X[indxs]\n",
        "    labels = y[indxs]\n",
        "\n",
        "    # Compute the weights of each point: w_i = (number of times i is sampled) / (sampleSize * prob(p_i))\n",
        "    weights = np.asarray(np.multiply(weights[indxs], counts), dtype=float).flatten()\n",
        "\n",
        "    weights = np.multiply(weights, 1.0 / (probability[indxs] * sample_size))\n",
        "    timeTaken = time.time() - startTime\n",
        "\n",
        "    return indxs, S, labels, weights, timeTaken"
      ],
      "metadata": {
        "id": "cj2QQUGpl9Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA"
      ],
      "metadata": {
        "id": "Py4_n97BnN-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "n_features = X.shape[1]\n",
        "n_components = max(1, n_features // 10)  # At least 1 component\n",
        "print(f\"Number of PCA components: {n_components}\")\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA(n_components=n_components)\n",
        "X_reduced = pca.fit_transform(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-OEW3uPnP2S",
        "outputId": "4ed8cbc3-d1f8-4d1a-92f1-042cf127fd5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PCA components: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "iH3fjZnwlxNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Lightweight coreset\n",
        "lwcs = LightweightCoreset(X, 10, 0.1)\n",
        "X_cs_lwc, w_cs_lwc = lwcs.compute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kucp-zKDU7DV",
        "outputId": "570ed972-444b-469c-d8e3-e5f18da9eb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coreset size:  58101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "## RBFNN coreset\n",
        "# ----- 1. scale to the unit ball (‖x‖₂ ≤ 1) ---------------------------------\n",
        "R = np.max(np.linalg.norm(X, axis=1))\n",
        "X_scaled = X / R            #  now every point satisfies ‖x‖₂ ≤ 1\n",
        "\n",
        "# ----- 2. lifting step  q_p = [‖x‖² , -2xᵀ , 1] ------------------------------\n",
        "phi = np.hstack([\n",
        "    np.sum(X_scaled**2, axis=1, keepdims=True),   # ‖x‖₂²\n",
        "    -2 * X_scaled,                                # -2 xᵀ\n",
        "    np.ones((X_scaled.shape[0], 1))               # 1\n",
        "])\n",
        "\n",
        "# ----- 3. sensitivities & coreset -------------------------------------------\n",
        "sens = obtainSensitivity(phi, w=None, approxMVEE=True)\n",
        "m = 58101                                        # coreset size\n",
        "idx, X_cs_rbfnn, labels, w_cs_rbfnn, _ = generateCoreset(phi, y, sens, m)\n",
        "print(f\"Coreset shape: {X_cs_rbfnn.shape}\")\n",
        "print(f\"Coreset labels shape: {labels.shape}\")\n",
        "print(f\"Coreset weights shape: {w_cs_rbfnn.shape}\")"
      ],
      "metadata": {
        "id": "KgvFLoOjmXDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_covtype\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def compute_quantization_error(X, centers):\n",
        "    # Assign each point to the nearest center\n",
        "    from scipy.spatial import distance\n",
        "    labels = np.argmin(distance.cdist(X, centers), axis=1)\n",
        "    # Squared distance from each point to its nearest center\n",
        "    distances = np.linalg.norm(X - centers[labels], axis=1) ** 2\n",
        "    return distances.sum()\n",
        "\n",
        "def kmeans_plus_plus_on_corset(X_cs, w_cs, k):\n",
        "    # Run kmeans++ on the weighted corset\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "    kmeans.fit(X_cs, sample_weight=w_cs)\n",
        "    centers = kmeans.cluster_centers_\n",
        "    return centers\n",
        "\n",
        "# Example usage:\n",
        "k = 10\n",
        "n_samples = X.shape[0]\n",
        "\n",
        "# 1. Full dataset\n",
        "kmeans_full = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "kmeans_full.fit(X)\n",
        "full_error = compute_quantization_error(X, kmeans_full.cluster_centers_)\n",
        "full_error_normalized = full_error / n_samples\n",
        "print(\"---------------FULL---------------\")\n",
        "print(f\"Quantization error on full dataset (k={k}): {full_error:.2f}\")\n",
        "print(f\"Normalized quantization error on full dataset (k={k}): {full_error_normalized:.6f}\")\n",
        "\n",
        "\n",
        "# 2. Find centers from corset for the lightweight coreset\n",
        "corset_centers = kmeans_plus_plus_on_corset(X_cs_lwc, w_cs_lwc, k)\n",
        "\n",
        "# Compute quantization error on full X based on these centers\n",
        "corset_error_full_X = compute_quantization_error(X, corset_centers)\n",
        "corset_error_full_X_normalized = corset_error_full_X / n_samples\n",
        "print(\"---------------Lightweight coreset---------------\")\n",
        "print(f\"Quantization error on full dataset using corset clusters (k={k}) with the lightweight method: {corset_error_full_X:.2f}\")\n",
        "print(f\"Normalized quantization error using corset clusters (k={k}) with the lightweight method: {corset_error_full_X_normalized:.6f}\")\n",
        "\n",
        "# 3. Find centers from corset for the rbfnn coreset\n",
        "X_cs_rbfnn_via_idx = X[idx]\n",
        "corset_centers = kmeans_plus_plus_on_corset(X_cs_rbfnn_via_idx, w_cs_rbfnn, k)\n",
        "\n",
        "# Compute quantization error on full X based on these centers\n",
        "corset_error_full_X = compute_quantization_error(X, corset_centers)\n",
        "corset_error_full_X_normalized = corset_error_full_X / n_samples\n",
        "print(\"---------------RBFNN corset---------------\")\n",
        "print(f\"Quantization error on full dataset using corset clusters (k={k}) with the RBFNN method: {corset_error_full_X:.2f}\")\n",
        "print(f\"Normalized quantization error using corset clusters (k={k}) with the RBFNN method: {corset_error_full_X_normalized:.6f}\")\n",
        "\n",
        "# 4. Find centers from corset for the PCA dataset\n",
        "kmeans_reduced = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "kmeans_reduced.fit(X_reduced)\n",
        "cluster_centers_original = pca.inverse_transform(kmeans_reduced.cluster_centers_)\n",
        "full_error = compute_quantization_error(X, cluster_centers_original)\n",
        "full_error_normalized = full_error / n_samples\n",
        "print(\"---------------PCA---------------\")\n",
        "print(f\"Quantization error on full dataset (k={k}): {full_error:.2f}\")\n",
        "print(f\"Normalized quantization error on full dataset (k={k}): {full_error_normalized:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWFoF8K9Voy0",
        "outputId": "8df64d05-a7c0-4e92-86da-034bee598c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------FULL---------------\n",
            "Quantization error on full dataset (k=10): 402018.09\n",
            "Normalized quantization error on full dataset (k=10): 0.691927\n",
            "---------------Lightweight coreset---------------\n",
            "Quantization error on full dataset using corset clusters (k=10) with the lightweight method: 394240.50\n",
            "Normalized quantization error using corset clusters (k=10) with the lightweight method: 0.678541\n",
            "---------------RBFNN corset---------------\n",
            "Quantization error on full dataset using corset clusters (k=10) with the RBFNN method: 414741.81\n",
            "Normalized quantization error using corset clusters (k=10) with the RBFNN method: 0.713827\n",
            "---------------PCA---------------\n",
            "Quantization error on full dataset (k=10): 504516.65\n",
            "Normalized quantization error on full dataset (k=10): 0.868341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G6XXGNVjqiaP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}