{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9SujbJttPOd"
      },
      "source": [
        "# function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q8LBs3KwG8Aa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet18\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# =======================\n",
        "# Dataset Loading\n",
        "# =======================\n",
        "def load_cifar10(batch_size=128):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return trainloader, testloader, trainset, testset\n",
        "\n",
        "# =======================\n",
        "# Feature Extraction\n",
        "# =======================\n",
        "def extract_features(model, dataloader, device='cuda'):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            features.append(outputs.cpu())\n",
        "            labels.append(targets)\n",
        "\n",
        "    all_features = torch.cat(features)\n",
        "    all_labels = torch.cat(labels)\n",
        "    return all_features, all_labels\n",
        "\n",
        "# =======================\n",
        "# KMeans Coreset Construction\n",
        "# =======================\n",
        "def kmeans_coreset(features, labels, k):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "    cluster_ids = kmeans.fit_predict(features.numpy())\n",
        "    centroids = torch.tensor(kmeans.cluster_centers_)\n",
        "\n",
        "    coreset_indices = []\n",
        "    for i in range(k):\n",
        "        cluster_points = features[cluster_ids == i]\n",
        "        if len(cluster_points) == 0:\n",
        "            continue\n",
        "        centroid = centroids[i]\n",
        "        distances = torch.norm(cluster_points - centroid, dim=1)\n",
        "        closest_idx = torch.argmin(distances)\n",
        "        original_indices = torch.where(torch.tensor(cluster_ids) == i)[0]\n",
        "        coreset_indices.append(original_indices[closest_idx].item())\n",
        "\n",
        "    return coreset_indices\n",
        "\n",
        "# =======================\n",
        "# PCA + KMeans Coreset Construction\n",
        "# =======================\n",
        "def pca_kmeans_coreset(features, labels, k, pca_dim=100):\n",
        "    pca = PCA(n_components=pca_dim)\n",
        "    features_pca = pca.fit_transform(features.numpy())\n",
        "    features_pca = torch.tensor(features_pca)\n",
        "\n",
        "    return kmeans_coreset(features_pca, labels, k)\n",
        "\n",
        "# =======================\n",
        "# Training Function\n",
        "# =======================\n",
        "def train_model(model, trainloader, optimizer, criterion, device='cuda', epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}')\n",
        "\n",
        "# =======================\n",
        "# Evaluation Function\n",
        "# =======================\n",
        "def evaluate_model(model, testloader, device='cuda'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy on test set: {100 * correct / total:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcGS05C8ijMT"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    batch_size: int = 128\n",
        "    learning_rate: float = 0.01\n",
        "    momentum: float = 0.9\n",
        "    weight_decay: float = 5e-4\n",
        "    num_epochs: int = 50\n",
        "    kmeans_k: int = 500\n",
        "    pca_dim: int = 100\n",
        "    random_seed: int = 42\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    n_classes: int = 10\n",
        "\n",
        "config = Config()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3UuviPCufB6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHEzXqToqAVk"
      },
      "source": [
        "# Increase the Coreset Size for kmeans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up8t-n2vilCn"
      },
      "outputs": [],
      "source": [
        "\n",
        "@dataclass\n",
        "class Config_kmeans:\n",
        "    batch_size: int = 128\n",
        "    learning_rate: float = 0.01\n",
        "    momentum: float = 0.9\n",
        "    weight_decay: float = 5e-4\n",
        "    num_epochs: int = 50\n",
        "    kmeans_k: int = 2000\n",
        "    pca_dim: int = 100\n",
        "    random_seed: int = 42\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    n_classes: int = 10\n",
        "\n",
        "config_kmeans = Config_kmeans()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN4lwO-Yp3mO"
      },
      "source": [
        "# Instead of picking only the closest point to the centroid (hard selection),sample multiple points near the centroid or with importance weighting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H29tvlR2hjvq"
      },
      "outputs": [],
      "source": [
        "def soft_kmeans_coreset(features, labels, k, points_per_cluster=5):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "    cluster_ids = kmeans.fit_predict(features.numpy())\n",
        "    centroids = torch.tensor(kmeans.cluster_centers_)\n",
        "\n",
        "    coreset_indices = []\n",
        "    for i in range(k):\n",
        "        cluster_points = features[cluster_ids == i]\n",
        "        if len(cluster_points) == 0:\n",
        "            continue\n",
        "        centroid = centroids[i]\n",
        "        distances = torch.norm(cluster_points - centroid, dim=1)\n",
        "\n",
        "        # Find top-k closest points (instead of just 1)\n",
        "        topk_indices = torch.topk(-distances, k=min(points_per_cluster, len(distances)))[1]\n",
        "\n",
        "        original_indices = torch.where(torch.tensor(cluster_ids) == i)[0]\n",
        "        selected_indices = original_indices[topk_indices]\n",
        "\n",
        "        coreset_indices.extend(selected_indices.tolist())\n",
        "\n",
        "    return coreset_indices\n",
        "\n",
        "\n",
        "def pca_soft_kmeans_coreset(features, labels, k, pca_dim=100):\n",
        "    pca = PCA(n_components=pca_dim)\n",
        "    features_pca = pca.fit_transform(features.numpy())\n",
        "    features_pca = torch.tensor(features_pca)\n",
        "\n",
        "    return soft_kmeans_coreset(features_pca, labels, k)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dByBfw6YfQSd"
      },
      "outputs": [],
      "source": [
        "def run_baseline_training(config):\n",
        "    trainloader, testloader, _, _ = load_cifar10(config.batch_size)\n",
        "    model = resnet18(num_classes=config.n_classes).to(config.device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config.learning_rate, momentum=config.momentum, weight_decay=config.weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_model(model, trainloader, optimizer, criterion, config.device, config.num_epochs)\n",
        "    evaluate_model(model, testloader, config.device)\n",
        "\n",
        "def run_kmeans_coreset_training(config):\n",
        "    trainloader, testloader, trainset, _ = load_cifar10(config.batch_size)\n",
        "    model_feat = resnet18(num_classes=config.n_classes)\n",
        "    model_feat.fc = nn.Identity()\n",
        "    model_feat = model_feat.to(config.device)\n",
        "\n",
        "    feature_loader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size, shuffle=False)\n",
        "    features, labels = extract_features(model_feat, feature_loader, config.device)\n",
        "\n",
        "    coreset_indices = kmeans_coreset(features, labels, config.kmeans_k)\n",
        "\n",
        "    selected_data = torch.utils.data.Subset(trainset, coreset_indices)\n",
        "    selected_loader = torch.utils.data.DataLoader(selected_data, batch_size=config.batch_size, shuffle=True)\n",
        "\n",
        "    model = resnet18(num_classes=config.n_classes).to(config.device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config.learning_rate, momentum=config.momentum, weight_decay=config.weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_model(model, selected_loader, optimizer, criterion, config.device, config.num_epochs)\n",
        "    evaluate_model(model, testloader, config.device)\n",
        "\n",
        "def run_pca_kmeans_coreset_training(config):\n",
        "    trainloader, testloader, trainset, _ = load_cifar10(config.batch_size)\n",
        "    model_feat = resnet18(num_classes=config.n_classes)\n",
        "    model_feat.fc = nn.Identity()\n",
        "    model_feat = model_feat.to(config.device)\n",
        "\n",
        "    feature_loader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size, shuffle=False)\n",
        "    features, labels = extract_features(model_feat, feature_loader, config.device)\n",
        "\n",
        "    coreset_indices = pca_kmeans_coreset(features, labels, config.kmeans_k, config.pca_dim)\n",
        "\n",
        "    selected_data = torch.utils.data.Subset(trainset, coreset_indices)\n",
        "    selected_loader = torch.utils.data.DataLoader(selected_data, batch_size=config.batch_size, shuffle=True)\n",
        "\n",
        "    model = resnet18(num_classes=config.n_classes).to(config.device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config.learning_rate, momentum=config.momentum, weight_decay=config.weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_model(model, selected_loader, optimizer, criterion, config.device, config.num_epochs)\n",
        "    evaluate_model(model, testloader, config.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35pmCkyMiEoO",
        "outputId": "f13f0777-ebbf-4b69-bd0e-81dc068717e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.5342\n",
            "Epoch 2, Loss: 1.1040\n",
            "Epoch 3, Loss: 0.8872\n",
            "Epoch 4, Loss: 0.7298\n",
            "Epoch 5, Loss: 0.6068\n",
            "Epoch 6, Loss: 0.5072\n",
            "Epoch 7, Loss: 0.4219\n",
            "Epoch 8, Loss: 0.3499\n",
            "Epoch 9, Loss: 0.2888\n",
            "Epoch 10, Loss: 0.2372\n",
            "Epoch 11, Loss: 0.2031\n",
            "Epoch 12, Loss: 0.1793\n",
            "Epoch 13, Loss: 0.1547\n",
            "Epoch 14, Loss: 0.1342\n",
            "Epoch 15, Loss: 0.1358\n",
            "Epoch 16, Loss: 0.1046\n",
            "Epoch 17, Loss: 0.1067\n",
            "Epoch 18, Loss: 0.0928\n",
            "Epoch 19, Loss: 0.0892\n",
            "Epoch 20, Loss: 0.0848\n",
            "Epoch 21, Loss: 0.0821\n",
            "Epoch 22, Loss: 0.0700\n",
            "Epoch 23, Loss: 0.0606\n",
            "Epoch 24, Loss: 0.0808\n",
            "Epoch 25, Loss: 0.0633\n",
            "Epoch 26, Loss: 0.0618\n",
            "Epoch 27, Loss: 0.0747\n",
            "Epoch 28, Loss: 0.0655\n",
            "Epoch 29, Loss: 0.0580\n",
            "Epoch 30, Loss: 0.0656\n",
            "Epoch 31, Loss: 0.0575\n",
            "Epoch 32, Loss: 0.0535\n",
            "Epoch 33, Loss: 0.0605\n",
            "Epoch 34, Loss: 0.0509\n",
            "Epoch 35, Loss: 0.0613\n",
            "Epoch 36, Loss: 0.0550\n",
            "Epoch 37, Loss: 0.0507\n",
            "Epoch 38, Loss: 0.0537\n",
            "Epoch 39, Loss: 0.0527\n",
            "Epoch 40, Loss: 0.0575\n",
            "Epoch 41, Loss: 0.0577\n",
            "Epoch 42, Loss: 0.0526\n",
            "Epoch 43, Loss: 0.0508\n",
            "Epoch 44, Loss: 0.0475\n",
            "Epoch 45, Loss: 0.0553\n",
            "Epoch 46, Loss: 0.0576\n",
            "Epoch 47, Loss: 0.0530\n",
            "Epoch 48, Loss: 0.0464\n",
            "Epoch 49, Loss: 0.0534\n",
            "Epoch 50, Loss: 0.0523\n",
            "Accuracy on test set: 73.01%\n"
          ]
        }
      ],
      "source": [
        "run_baseline_training(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtudqqYViGrI",
        "outputId": "6adb0a38-3251-4abc-f55e-bc7090a031f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:33<00:00, 5.11MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 2.1909\n",
            "Epoch 2, Loss: 1.6674\n",
            "Epoch 3, Loss: 1.2655\n",
            "Epoch 4, Loss: 0.8775\n",
            "Epoch 5, Loss: 0.5848\n",
            "Epoch 6, Loss: 0.4309\n",
            "Epoch 7, Loss: 0.3058\n",
            "Epoch 8, Loss: 0.2435\n",
            "Epoch 9, Loss: 0.2173\n",
            "Epoch 10, Loss: 0.1759\n",
            "Epoch 11, Loss: 0.1237\n",
            "Epoch 12, Loss: 0.1202\n",
            "Epoch 13, Loss: 0.1026\n",
            "Epoch 14, Loss: 0.0947\n",
            "Epoch 15, Loss: 0.0624\n",
            "Epoch 16, Loss: 0.0426\n",
            "Epoch 17, Loss: 0.0253\n",
            "Epoch 18, Loss: 0.0355\n",
            "Epoch 19, Loss: 0.0298\n",
            "Epoch 20, Loss: 0.0270\n",
            "Epoch 21, Loss: 0.0156\n",
            "Epoch 22, Loss: 0.0113\n",
            "Epoch 23, Loss: 0.0045\n",
            "Epoch 24, Loss: 0.0033\n",
            "Epoch 25, Loss: 0.0054\n",
            "Epoch 26, Loss: 0.0063\n",
            "Epoch 27, Loss: 0.0025\n",
            "Epoch 28, Loss: 0.0017\n",
            "Epoch 29, Loss: 0.0007\n",
            "Epoch 30, Loss: 0.0011\n",
            "Epoch 31, Loss: 0.0006\n",
            "Epoch 32, Loss: 0.0004\n",
            "Epoch 33, Loss: 0.0004\n",
            "Epoch 34, Loss: 0.0004\n",
            "Epoch 35, Loss: 0.0004\n",
            "Epoch 36, Loss: 0.0004\n",
            "Epoch 37, Loss: 0.0003\n",
            "Epoch 38, Loss: 0.0003\n",
            "Epoch 39, Loss: 0.0003\n",
            "Epoch 40, Loss: 0.0003\n",
            "Epoch 41, Loss: 0.0003\n",
            "Epoch 42, Loss: 0.0002\n",
            "Epoch 43, Loss: 0.0003\n",
            "Epoch 44, Loss: 0.0003\n",
            "Epoch 45, Loss: 0.0003\n",
            "Epoch 46, Loss: 0.0002\n",
            "Epoch 47, Loss: 0.0002\n",
            "Epoch 48, Loss: 0.0003\n",
            "Epoch 49, Loss: 0.0003\n",
            "Epoch 50, Loss: 0.0002\n",
            "Accuracy on test set: 41.71%\n"
          ]
        }
      ],
      "source": [
        "run_kmeans_coreset_training(config_kmeans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Btj0CtuhiIN2",
        "outputId": "71ed7f7d-b27a-43ad-e9b3-7f86d7752bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 2.2247\n",
            "Epoch 2, Loss: 1.7510\n",
            "Epoch 3, Loss: 1.2819\n",
            "Epoch 4, Loss: 0.8985\n",
            "Epoch 5, Loss: 0.5507\n",
            "Epoch 6, Loss: 0.3583\n",
            "Epoch 7, Loss: 0.3079\n",
            "Epoch 8, Loss: 0.2779\n",
            "Epoch 9, Loss: 0.2515\n",
            "Epoch 10, Loss: 0.1854\n",
            "Epoch 11, Loss: 0.1455\n",
            "Epoch 12, Loss: 0.1510\n",
            "Epoch 13, Loss: 0.0985\n",
            "Epoch 14, Loss: 0.0893\n",
            "Epoch 15, Loss: 0.0589\n",
            "Epoch 16, Loss: 0.0444\n",
            "Epoch 17, Loss: 0.0519\n",
            "Epoch 18, Loss: 0.0490\n",
            "Epoch 19, Loss: 0.0513\n",
            "Epoch 20, Loss: 0.0403\n",
            "Epoch 21, Loss: 0.0385\n",
            "Epoch 22, Loss: 0.0401\n",
            "Epoch 23, Loss: 0.0251\n",
            "Epoch 24, Loss: 0.0445\n",
            "Epoch 25, Loss: 0.0315\n",
            "Epoch 26, Loss: 0.0341\n",
            "Epoch 27, Loss: 0.0218\n",
            "Epoch 28, Loss: 0.0202\n",
            "Epoch 29, Loss: 0.0142\n",
            "Epoch 30, Loss: 0.0175\n",
            "Epoch 31, Loss: 0.0108\n",
            "Epoch 32, Loss: 0.0053\n",
            "Epoch 33, Loss: 0.0026\n",
            "Epoch 34, Loss: 0.0055\n",
            "Epoch 35, Loss: 0.0035\n",
            "Epoch 36, Loss: 0.0017\n",
            "Epoch 37, Loss: 0.0010\n",
            "Epoch 38, Loss: 0.0006\n",
            "Epoch 39, Loss: 0.0004\n",
            "Epoch 40, Loss: 0.0003\n",
            "Epoch 41, Loss: 0.0003\n",
            "Epoch 42, Loss: 0.0003\n",
            "Epoch 43, Loss: 0.0003\n",
            "Epoch 44, Loss: 0.0003\n",
            "Epoch 45, Loss: 0.0003\n",
            "Epoch 46, Loss: 0.0003\n",
            "Epoch 47, Loss: 0.0002\n",
            "Epoch 48, Loss: 0.0002\n",
            "Epoch 49, Loss: 0.0002\n",
            "Epoch 50, Loss: 0.0002\n",
            "Accuracy on test set: 43.07%\n"
          ]
        }
      ],
      "source": [
        "run_pca_kmeans_coreset_training(config_kmeans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31Fd2bwSo2c-"
      },
      "outputs": [],
      "source": [
        "def run_soft_kmeans_coreset_training(config):\n",
        "    trainloader, testloader, trainset, _ = load_cifar10(config.batch_size)\n",
        "    model_feat = resnet18(num_classes=config.n_classes)\n",
        "    model_feat.fc = nn.Identity()\n",
        "    model_feat = model_feat.to(config.device)\n",
        "\n",
        "    feature_loader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size, shuffle=False)\n",
        "    features, labels = extract_features(model_feat, feature_loader, config.device)\n",
        "\n",
        "    coreset_indices = soft_kmeans_coreset(features, labels, config.kmeans_k)\n",
        "\n",
        "    selected_data = torch.utils.data.Subset(trainset, coreset_indices)\n",
        "    selected_loader = torch.utils.data.DataLoader(selected_data, batch_size=config.batch_size, shuffle=True)\n",
        "\n",
        "    model = resnet18(num_classes=config.n_classes).to(config.device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config.learning_rate, momentum=config.momentum, weight_decay=config.weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_model(model, selected_loader, optimizer, criterion, config.device, config.num_epochs)\n",
        "    evaluate_model(model, testloader, config.device)\n",
        "\n",
        "def run_pca_soft_kmeans_coreset_training(config):\n",
        "    trainloader, testloader, trainset, _ = load_cifar10(config.batch_size)\n",
        "    model_feat = resnet18(num_classes=config.n_classes)\n",
        "    model_feat.fc = nn.Identity()\n",
        "    model_feat = model_feat.to(config.device)\n",
        "\n",
        "    feature_loader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size, shuffle=False)\n",
        "    features, labels = extract_features(model_feat, feature_loader, config.device)\n",
        "\n",
        "    coreset_indices = pca_soft_kmeans_coreset(features, labels, config.kmeans_k, config.pca_dim)\n",
        "\n",
        "    selected_data = torch.utils.data.Subset(trainset, coreset_indices)\n",
        "    selected_loader = torch.utils.data.DataLoader(selected_data, batch_size=config.batch_size, shuffle=True)\n",
        "\n",
        "    model = resnet18(num_classes=config.n_classes).to(config.device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config.learning_rate, momentum=config.momentum, weight_decay=config.weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_model(model, selected_loader, optimizer, criterion, config.device, config.num_epochs)\n",
        "    evaluate_model(model, testloader, config.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4fwNx-Xphy8",
        "outputId": "8fa5cc4f-6d88-49f6-e660-3ce3761dfeb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.8902\n",
            "Epoch 2, Loss: 1.4678\n",
            "Epoch 3, Loss: 1.2376\n",
            "Epoch 4, Loss: 1.0480\n",
            "Epoch 5, Loss: 0.8838\n",
            "Epoch 6, Loss: 0.7357\n",
            "Epoch 7, Loss: 0.5620\n",
            "Epoch 8, Loss: 0.4868\n",
            "Epoch 9, Loss: 0.4010\n",
            "Epoch 10, Loss: 0.3099\n",
            "Epoch 11, Loss: 0.2272\n",
            "Epoch 12, Loss: 0.1637\n",
            "Epoch 13, Loss: 0.2395\n",
            "Epoch 14, Loss: 0.2504\n",
            "Epoch 15, Loss: 0.1757\n",
            "Epoch 16, Loss: 0.0511\n",
            "Epoch 17, Loss: 0.0461\n",
            "Epoch 18, Loss: 0.1111\n",
            "Epoch 19, Loss: 0.1114\n",
            "Epoch 20, Loss: 0.0761\n",
            "Epoch 21, Loss: 0.0563\n",
            "Epoch 22, Loss: 0.0819\n",
            "Epoch 23, Loss: 0.0383\n",
            "Epoch 24, Loss: 0.0419\n",
            "Epoch 25, Loss: 0.0598\n",
            "Epoch 26, Loss: 0.0332\n",
            "Epoch 27, Loss: 0.0231\n",
            "Epoch 28, Loss: 0.0505\n",
            "Epoch 29, Loss: 0.0598\n",
            "Epoch 30, Loss: 0.1392\n",
            "Epoch 31, Loss: 0.0572\n",
            "Epoch 32, Loss: 0.0401\n",
            "Epoch 33, Loss: 0.0208\n",
            "Epoch 34, Loss: 0.0127\n",
            "Epoch 35, Loss: 0.0095\n",
            "Epoch 36, Loss: 0.0031\n",
            "Epoch 37, Loss: 0.0017\n",
            "Epoch 38, Loss: 0.0008\n",
            "Epoch 39, Loss: 0.0007\n",
            "Epoch 40, Loss: 0.0004\n",
            "Epoch 41, Loss: 0.0004\n",
            "Epoch 42, Loss: 0.0004\n",
            "Epoch 43, Loss: 0.0004\n",
            "Epoch 44, Loss: 0.0004\n",
            "Epoch 45, Loss: 0.0003\n",
            "Epoch 46, Loss: 0.0004\n",
            "Epoch 47, Loss: 0.0004\n",
            "Epoch 48, Loss: 0.0003\n",
            "Epoch 49, Loss: 0.0003\n",
            "Epoch 50, Loss: 0.0002\n",
            "Accuracy on test set: 57.65%\n"
          ]
        }
      ],
      "source": [
        "run_soft_kmeans_coreset_training(config_kmeans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF2Gb3KNpjh7",
        "outputId": "bdc83562-30dc-494b-9ca6-4c18bb34aa99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.8792\n",
            "Epoch 2, Loss: 1.4444\n",
            "Epoch 3, Loss: 1.1691\n",
            "Epoch 4, Loss: 0.9885\n",
            "Epoch 5, Loss: 0.8104\n",
            "Epoch 6, Loss: 0.6702\n",
            "Epoch 7, Loss: 0.5104\n",
            "Epoch 8, Loss: 0.4331\n",
            "Epoch 9, Loss: 0.3727\n",
            "Epoch 10, Loss: 0.2420\n",
            "Epoch 11, Loss: 0.1902\n",
            "Epoch 12, Loss: 0.1502\n",
            "Epoch 13, Loss: 0.1554\n",
            "Epoch 14, Loss: 0.1462\n",
            "Epoch 15, Loss: 0.1095\n",
            "Epoch 16, Loss: 0.0803\n",
            "Epoch 17, Loss: 0.0841\n",
            "Epoch 18, Loss: 0.0637\n",
            "Epoch 19, Loss: 0.0434\n",
            "Epoch 20, Loss: 0.0389\n",
            "Epoch 21, Loss: 0.0356\n",
            "Epoch 22, Loss: 0.0318\n",
            "Epoch 23, Loss: 0.0359\n",
            "Epoch 24, Loss: 0.0432\n",
            "Epoch 25, Loss: 0.0369\n",
            "Epoch 26, Loss: 0.0427\n",
            "Epoch 27, Loss: 0.0338\n",
            "Epoch 28, Loss: 0.0356\n",
            "Epoch 29, Loss: 0.0359\n",
            "Epoch 30, Loss: 0.0376\n",
            "Epoch 31, Loss: 0.0577\n",
            "Epoch 32, Loss: 0.0538\n",
            "Epoch 33, Loss: 0.0442\n",
            "Epoch 34, Loss: 0.0184\n",
            "Epoch 35, Loss: 0.0119\n",
            "Epoch 36, Loss: 0.0056\n",
            "Epoch 37, Loss: 0.0044\n",
            "Epoch 38, Loss: 0.0056\n",
            "Epoch 39, Loss: 0.0024\n",
            "Epoch 40, Loss: 0.0015\n",
            "Epoch 41, Loss: 0.0008\n",
            "Epoch 42, Loss: 0.0007\n",
            "Epoch 43, Loss: 0.0007\n",
            "Epoch 44, Loss: 0.0004\n",
            "Epoch 45, Loss: 0.0003\n",
            "Epoch 46, Loss: 0.0003\n",
            "Epoch 47, Loss: 0.0003\n",
            "Epoch 48, Loss: 0.0002\n",
            "Epoch 49, Loss: 0.0002\n",
            "Epoch 50, Loss: 0.0003\n",
            "Accuracy on test set: 56.68%\n"
          ]
        }
      ],
      "source": [
        "run_pca_soft_kmeans_coreset_training(config_kmeans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUw5nXPbqZ56"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ffcv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
